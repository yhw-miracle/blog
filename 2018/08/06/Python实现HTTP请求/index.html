<html>
  <head><meta name="generator" content="Hexo 3.8.0">
    <title>Python实现HTTP请求 - 痛点就是起点</title>
    <link href="/images/fav.png" rel="shortcut icon">
<link href="/atom.xml" rel="alternate" type="application/rss+xml">
<link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/highlight.css">
<link rel="stylesheet" href="/css/responsive.css">
<script src="/js/jquery.js"></script>
<script src="/js/basics.js"></script>
<meta content="width=device-width, initial-scale=1.0, user-scalable=no" name="viewport">
<meta content="text/html; charset=utf-8" http-equiv="content-type">


  </head>
  <body>
    <header>
  <a id="go-back-home" href="/"><img src="/images/logo.jpg" alt="Home" width="53" height="59"></a>
  <p>痛点就是起点</p>
  <p>Speaking is as important as doing!</p>
</header>

    <div id="container">
      <div class="block">
  
    <a class="main" href="/">Home</a>
  
    <a class="main" href="/ToYou">ToYou</a>
  
    <a class="main" href="/categories">Categories</a>
  
    <a class="main" href="/atom.xml">RSS</a>
  
</div>

      <section class="paging">
  
    <div class="left">
      <a href="/2018/08/07/正则表达式/">
        ‹
      </a>
    </div>
  
  
    <div class="right">
      <a href="/2018/08/05/学一点XPath/">
        ›
      </a>
    </div>
  
</section>

      <div class="content">
        <section class="post">
          <h1>
            <div class="date">2018-08-06</div>
            Python实现HTTP请求
          </h1>
          <p>python　中实现 HTTP 请求有三种方式，分别为 urllib2/urllib、httplib/urllib 和 Requests。</p>
<h3 id="1-urllib2-urllib"><a href="#1-urllib2-urllib" class="headerlink" title="1. urllib2/urllib"></a>1. urllib2/urllib</h3><h4 id="1-1-基本请求和响应模型"><a href="#1-1-基本请求和响应模型" class="headerlink" title="1.1 基本请求和响应模型"></a>1.1 基本请求和响应模型</h4><p>urllib2 和 urllib 是 Python 中的两个内置模块，实现 HTTP 请求时，以 urllib2 为主，urllib　为辅。urllib2 模块提供了 urliopen() 方法，可以向指定的 URL 发出请求来获取数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求</span></span><br><span class="line">request = urllib2.Request(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 响应</span></span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> response.read()</span><br></pre></td></tr></table></figure>
<h4 id="1-2-请求头-headers-处理"><a href="#1-2-请求头-headers-处理" class="headerlink" title="1.2 请求头 headers 处理"></a>1.2 请求头 headers 处理</h4><p>请求头信息可以直接与 URL 一起放到 Requset() 方法里，也可以使用 add_header() 方法添加请求头信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://github.com/login"</span></span><br><span class="line">userAgent = <span class="string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span></span><br><span class="line">referer = <span class="string">'https://github.com'</span></span><br><span class="line">postData = &#123;<span class="string">'username'</span>: <span class="string">'111'</span>, <span class="string">'passowrd'</span>: <span class="string">'222'</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 userAgent, referer 写入头信息</span></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>: userAgent, <span class="string">'Referer'</span>: referer&#125;</span><br><span class="line"></span><br><span class="line">data = urllib.urlencode(postData)</span><br><span class="line">request = urllib2.Request(url, data, headers)</span><br><span class="line"><span class="comment"># request.add_header('User-Agent', userAgent)</span></span><br><span class="line"><span class="comment"># request.add_header('Referer', referer)</span></span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"><span class="keyword">print</span> response.read()</span><br></pre></td></tr></table></figure>
<h4 id="1-3-Cookie-处理"><a href="#1-3-Cookie-处理" class="headerlink" title="1.3 Cookie 处理"></a>1.3 Cookie 处理</h4><p>urllib2 对 Cookie 的处理是自动的，使用 CookieJar 函数进行 Cookie 的管理。我们也可以通过设置请求头中的 Cookie 域来自定义添加 Cookie 的内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> cookielib</span><br><span class="line"></span><br><span class="line">cookie = cookielib.CookieJar()</span><br><span class="line">opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> cookie:</span><br><span class="line">    <span class="keyword">print</span> item.name + <span class="string">':'</span> + item.value</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> cookielib</span><br><span class="line"></span><br><span class="line">cookie = cookielib.CookieJar()</span><br><span class="line">opener = urllib2.build_opener()</span><br><span class="line">opener.addheaders.append((<span class="string">'cookie'</span>, <span class="string">'email='</span>+<span class="string">"xxx@163.com"</span>))</span><br><span class="line">request = urllib2.Request(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">response = opener.open(request)</span><br><span class="line"><span class="keyword">print</span> response.headers</span><br><span class="line"><span class="keyword">print</span> response.read()</span><br></pre></td></tr></table></figure>
<h4 id="1-4-设置超时处理的三种方法"><a href="#1-4-设置超时处理的三种方法" class="headerlink" title="1.4 设置超时处理的三种方法"></a>1.4 设置超时处理的三种方法</h4><p>在 python2.6 之前的版本，urllib2 的 API 并没有 Timeout 的设置，要设置 Timeout 值，只能通过设置 Socket 的全局 Timeout 值实现。而在 python2.6 及新的版本中，urlopen() 函数提供了对 Timeout 的设置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"><span class="comment"># way 1</span></span><br><span class="line">socket.setdefaulttimeout(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># way 2</span></span><br><span class="line">urllib2.socket.setdefaulttimeout(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># way 3</span></span><br><span class="line">request = urllib2.Request(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">response = urllib2.urlopen(request, timeout=<span class="number">2</span>)</span><br><span class="line"><span class="keyword">print</span> response.read()</span><br></pre></td></tr></table></figure>
<h4 id="1-5-获取-HTTP-响应码"><a href="#1-5-获取-HTTP-响应码" class="headerlink" title="1.5 获取 HTTP 响应码"></a>1.5 获取 HTTP 响应码</h4><p>对于 200 OK 来说，urlopen() 方法返回的 response 对象的 getcode() 方法可以得到该 HTTP 响应码，但是对于其他类型的响应码，urlopen() 方法会抛出异常，这样需要通过异常对象来获取响应码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line">response = urllib2.urlopen(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"><span class="keyword">print</span> response.getcode()</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = urllib2.urlopen(<span class="string">'http://www.google.com'</span>, timeout=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">print</span> response</span><br><span class="line"><span class="keyword">except</span> urllib2.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">if</span> hasattr(e, <span class="string">'code'</span>):</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'Error code:'</span>, e.code</span><br></pre></td></tr></table></figure>
<h4 id="1-6-重定向"><a href="#1-6-重定向" class="headerlink" title="1.6 重定向"></a>1.6 重定向</h4><p>urllib2 默认情况下会针对 HTTP 3XX 返回码自动进行重定向动作。要检测是否发生了重定向动作，只要检查一些 Response 的 URL 和 Resquest 的 URL 是否一致就可以了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line">response = urllib2.urlopen(<span class="string">'http://www.zhihu.com'</span>)</span><br><span class="line">isRedirected = response.geturl() == <span class="string">'http://www.zhihu.com'</span></span><br><span class="line"><span class="keyword">print</span> isRedirected</span><br></pre></td></tr></table></figure>
<p>如果不想自动重定向，可以自定义 HTTPRedirectHandler 类实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedirectHandler</span><span class="params">(urllib2.HTTPRedirectHandler)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">http_error_301</span><span class="params">(self, req, fp, code, msg, headers)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">http_error_302</span><span class="params">(self, req, fp, code, msg, headers)</span>:</span></span><br><span class="line">        result = urllib2.HTTPRedirectHandler.http_error_301(self, req, fp, code, msg, headers)</span><br><span class="line">        result.status = code</span><br><span class="line">        result.newurl = result.geturl()</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">opener = urllib2.build_opener(RedirectHandler)</span><br><span class="line">opener.open(<span class="string">'http://www.zhihu.com'</span>)</span><br></pre></td></tr></table></figure>
<h4 id="1-7-Proxy-代理"><a href="#1-7-Proxy-代理" class="headerlink" title="1.7 Proxy 代理"></a>1.7 Proxy 代理</h4><p>urllib2 默认使用环境变量 http_proxy 来设置 HTTP Proxy；也可以使用 ProxyHandler 在程序中动态设置代理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line">proxy = urllib2.ProxyHandler(&#123;<span class="string">'http'</span>: <span class="string">'127.0.0.1:8087'</span>&#125;)</span><br><span class="line">opener = urllib2.build_opener([proxy, ])</span><br><span class="line">urllib2.install_opener(opener)</span><br><span class="line">response = urllib2.urlopen(<span class="string">'http://www.zhihu.com'</span>)</span><br><span class="line"><span class="keyword">print</span> response.read()</span><br></pre></td></tr></table></figure>
<p>使用 urllib2.install_opener() 方法会全局设置代理，不利于更细粒度的控制，可以使用 opener.open() 代替全局的 urlopen()　方法使用不同的代理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line">proxy = urllib2.ProxyHandler(&#123;<span class="string">'http'</span>: <span class="string">'127.0.0.1:8087'</span>&#125;)</span><br><span class="line">opener = urllib2.build_opener(proxy, )</span><br><span class="line">response = opener.open(<span class="string">'http://www.zhihu.com'</span>)</span><br><span class="line"><span class="keyword">print</span> response.read()</span><br></pre></td></tr></table></figure>
<h3 id="2-httplib-urllib"><a href="#2-httplib-urllib" class="headerlink" title="2. httplib/urllib"></a>2. httplib/urllib</h3><p>httplib 模块是一个底层基础模块，可以了解建立 HTTP 请求的每一步，正常情况下开发用的很少。</p>
<table>
<thead>
<tr>
<th>功能</th>
<th>API</th>
</tr>
</thead>
<tbody>
<tr>
<td>创建 HTTPConnection 对象</td>
<td>httplib.HTTPConnection(host[.port,[strict[,timeout[,source_address]]]])</td>
</tr>
<tr>
<td>发送请求</td>
<td>HTTPConnection.request(method,url[,body[,headers]])</td>
</tr>
<tr>
<td>获得响应</td>
<td>HTTPConnection.getresponse()</td>
</tr>
<tr>
<td>读取响应信息</td>
<td>HTTPResponse.read()</td>
</tr>
<tr>
<td>获取指定请求头信息</td>
<td>HTTPResponse.getheader(name[,default])</td>
</tr>
<tr>
<td>获取响应头，以 (header, value) 元组构成的列表返回</td>
<td>HTTPResponse.getheaders()</td>
</tr>
<tr>
<td>获取底层 socket 文件描述符</td>
<td>HTTPResponse.fileno()</td>
</tr>
<tr>
<td>获取头内容</td>
<td>HTTPResponse.msg</td>
</tr>
<tr>
<td>获取头 http 版本</td>
<td>HTTPResponse.version</td>
</tr>
<tr>
<td>获取返回状态码</td>
<td>HTTPResponse.status</td>
</tr>
<tr>
<td>获取返回说明</td>
<td>HTTPResponse.reason</td>
</tr>
</tbody>
</table>
<h3 id="3-Requests"><a href="#3-Requests" class="headerlink" title="3. Requests"></a>3. Requests</h3><h4 id="3-1-Requests-安装"><a href="#3-1-Requests-安装" class="headerlink" title="3.1 Requests 安装"></a>3.1 Requests 安装</h4><p>Python 中 Requests 模块实现 HTTP　请求的方式非常简单，操作更加人性化。Requests 库是第三方模块，需要额外安装，其源码开源，位于 <a href="https://github.com/requests/requests" target="_blank" rel="noopener">Github</a> 上。安装 requests 方式有两种：</p>
<blockquote>
<ol>
<li>直接在 Terminal 上输入命令 pip install requests</li>
<li>下载 <a href="https://github.com/requests/requests/releases" target="_blank" rel="noopener">requests 源码</a>，然后解压，在 Terminal 中进入解压后的目录，运行 setup.py 文件即可。</li>
</ol>
</blockquote>
<h4 id="3-2-基本请求和响应模型"><a href="#3-2-基本请求和响应模型" class="headerlink" title="3.2 基本请求和响应模型"></a>3.2 基本请求和响应模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># get 请求</span></span><br><span class="line">req = requests.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">print(req.content)</span><br><span class="line"></span><br><span class="line"><span class="comment"># post 请求</span></span><br><span class="line">postData = &#123;<span class="string">'key'</span>: <span class="string">'value'</span>&#125;</span><br><span class="line">req = requests.post(<span class="string">'http://www.xxx.com/login'</span>, postData)</span><br><span class="line">print(req.content)</span><br><span class="line"></span><br><span class="line"><span class="comment"># https://zzk.cnblogs.com/s/blogpost?Keywords=blog:qiyeboy&amp;pageindex=1</span></span><br><span class="line"><span class="comment"># 处理 ? 后面的参数</span></span><br><span class="line">payload = &#123;<span class="string">'Keywords'</span>: <span class="string">'blog:qiyeboy'</span>, <span class="string">'pageindex'</span>: <span class="number">1</span>&#125;</span><br><span class="line">req = requests.get(<span class="string">'https://zzk.cnblogs.com/s/blogpost'</span>, params=payload)</span><br><span class="line">print(req.url)</span><br></pre></td></tr></table></figure>
<h4 id="3-3-响应码-code-和请求头-headers-处理"><a href="#3-3-响应码-code-和请求头-headers-处理" class="headerlink" title="3.3 响应码 code 和请求头 headers 处理"></a>3.3 响应码 code 和请求头 headers 处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">req = requests.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"><span class="keyword">if</span> req.status_code == requests.codes.ok:</span><br><span class="line">    print(req.status_code)   <span class="comment"># 响应码</span></span><br><span class="line">    print(req.headers)   <span class="comment"># 响应头</span></span><br><span class="line">    print(req.headers.get(<span class="string">'content-type'</span>))</span><br><span class="line">    print(req.headers[<span class="string">'content-type'</span>])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    req.raise_for_status()</span><br></pre></td></tr></table></figure>
<h4 id="3-4-Cookie-处理"><a href="#3-4-Cookie-处理" class="headerlink" title="3.4 Cookie 处理"></a>3.4 Cookie 处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">userAgent = <span class="string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>: userAgent&#125;</span><br><span class="line">req = requests.get(<span class="string">'http://www.baidu.com'</span>, headers=headers)</span><br><span class="line"><span class="keyword">for</span> cookie <span class="keyword">in</span> req.cookies.keys():</span><br><span class="line">    print(cookie + <span class="string">':'</span> + req.cookies.get(cookie))</span><br><span class="line"></span><br><span class="line">userAgent = <span class="string">'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'</span></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>: userAgent&#125;</span><br><span class="line">cookies = dict(name=<span class="string">'qiye'</span>, age=<span class="string">'10'</span>)</span><br><span class="line"><span class="comment"># 发送 cookie</span></span><br><span class="line">req = requests.get(<span class="string">'http://www.baidu.com'</span>, headers=headers, cookies=cookies)</span><br><span class="line"></span><br><span class="line">loginUrl = <span class="string">'http://www.xxx.com/login'</span></span><br><span class="line">s = requests.session()</span><br><span class="line"><span class="comment"># 首先访问登录页面，作为游客，服务器会先分配一个 cookie</span></span><br><span class="line">req = s.get(loginUrl, allow_redirects=<span class="keyword">True</span>)</span><br><span class="line">datas = &#123;<span class="string">'name'</span>: <span class="string">'qiye'</span>, <span class="string">'passwd'</span>: <span class="string">'qiye'</span>&#125;</span><br><span class="line"><span class="comment"># 向登录链接发送 post 请求，验证成功，游客权限转为会员权限</span></span><br><span class="line">req = s.post(loginUrl, data=datas, allow_redirects=<span class="keyword">True</span>)</span><br><span class="line">print(req.text)</span><br></pre></td></tr></table></figure>
<h4 id="3-5-重定向与历史信息"><a href="#3-5-重定向与历史信息" class="headerlink" title="3.5 重定向与历史信息"></a>3.5 重定向与历史信息</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># allow_redirects=True 允许重定向，默认允许</span></span><br><span class="line"><span class="comment"># requests.get('', allow_redirects=True)</span></span><br><span class="line">req = requests.get(<span class="string">'http://github.com'</span>)</span><br><span class="line">print(req.url)</span><br><span class="line">print(req.status_code)</span><br><span class="line">print(req.history)</span><br></pre></td></tr></table></figure>
<h4 id="3-6-超时设置"><a href="#3-6-超时设置" class="headerlink" title="3.6 超时设置"></a>3.6 超时设置</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">print(requests.get(<span class="string">'http://www.google.com'</span>, timeout=<span class="number">5</span>).content)</span><br></pre></td></tr></table></figure>
<h4 id="3-7-代理设置"><a href="#3-7-代理设置" class="headerlink" title="3.7 代理设置"></a>3.7 代理设置</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">"http"</span>: <span class="string">"http://0.10.1.10:3128"</span>,</span><br><span class="line">    <span class="string">"https"</span>: <span class="string">"http://10.10.1.10:1080"</span>,</span><br><span class="line">&#125;</span><br><span class="line">requests.get(<span class="string">'http://example.org'</span>, proxies=proxies)</span><br></pre></td></tr></table></figure>

          <br>
<p> from yhw-miracle</p>
<p align="center"><img src="/images/qrcode_for_gh_5efb2780ab44_258.jpg" alt="痛点就是起点"></p>
<p align="center">算法和代码的世界不仅是学习的痛点，而且是成功的起点。欢迎关注，共同进步！</p>

        </section>
      </div>
      
      <!--<div class="block">
  
    <a class="main" href="/">Home</a>
  
    <a class="main" href="/ToYou">ToYou</a>
  
    <a class="main" href="/categories">Categories</a>
  
    <a class="main" href="/atom.xml">RSS</a>
  
</div>
-->
    </div>
    <footer>
  <span class="muted">&copy; 2016 - 2019 yhw-miracle. All Rights Reserved.</span><br>
  <!--<a href='https://github.com/saintwinkle/hexo-theme-scribble' class='muted'>built with Hexo using Scribble theme</a>-->
  <img src="/images/logo.jpg" width="53" height="59" alt="痛点就是起点">
</footer>

  </body>
</html>
