<html>
  <head><meta name="generator" content="Hexo 3.8.0">
    <title>详解基础爬虫架构 - 痛点就是起点</title>
    <link href="/images/logo.jpg" rel="shortcut icon">
<link href="/atom.xml" rel="alternate" type="application/rss+xml">
<link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/highlight.css">
<link rel="stylesheet" href="/css/responsive.css">
<script src="/js/jquery.js"></script>
<script src="/js/basics.js"></script>
<meta content="width=device-width, initial-scale=1.0, user-scalable=no" name="viewport">
<meta content="text/html; charset=utf-8" http-equiv="content-type">


  </head>
  <body>
    <header>
  <a id="go-back-home" href="/"><img src="/images/logo.jpg" alt="Home" width="53" height="59"></a>
  <p>痛点就是起点</p>
  <p>Speaking is as important as doing!</p>
</header>

    <div id="container">
      <div class="block">
  
    <a class="main" href="/">Home</a>
  
    <a class="main" href="/ToYou">ToYou</a>
  
    <a class="main" href="/categories">Categories</a>
  
    <a class="main" href="/atom.xml">RSS</a>
  
</div>

      <section class="paging">
  
    <div class="left">
      <a href="/2019/04/01/learning-python-01/">
        ‹
      </a>
    </div>
  
  
    <div class="right">
      <a href="/2019/01/15/python实现邮件发送/">
        ›
      </a>
    </div>
  
</section>

      <div class="content">
        <section class="post">
          <h1>
            <div class="date">2019-01-15</div>
            详解基础爬虫架构
          </h1>
          <p>基础爬虫框架主要包括五大模块，分别为<code>URL</code>管理器、<code>HTML</code>下载器、<code>HTML</code>解析器、数据存储器和爬虫调度器。它们之间关系如下图所示。</p>
<p><img src="/images/2019/Jan/2.png" alt=""></p>
<p><code>URL</code>管理器负责管理<code>URL</code>链接，维护已爬取的<code>URL</code>集合和为未爬取的<code>URL</code>集合，并提供外部访问接口。</p>
<p><code>HTML</code>下载器负责从<code>URL</code>管理器中获取未爬取的<code>URL</code>链接，并下载相应的<code>HTML</code>网页。</p>
<p><code>HTML</code>解析器负责解析<code>HTML</code>下载器下载的网页信息，解析出的信息交给数据存储器，解析出的新的<code>URL</code>链接交给<code>URL</code>管理器。</p>
<p>数据存储器负责将<code>HTML</code>解析器解析出来的数据通过文件或数据库的形式存储起来。</p>
<p>爬虫调度器负责统筹以上四个模块之间协调工作。</p>
<p>以爬取百度百科<code>100</code>条词条的词条标题、摘要和链接为例。</p>
<h3 id="URL管理器"><a href="#URL管理器" class="headerlink" title="URL管理器"></a><code>URL</code>管理器</h3><p><code>URL</code>管理器维护了两个变量，已爬取<code>URL</code>集合和未爬取<code>URL</code>集合；对外提供了四类访问这两个变量的方法，包括是否有待爬取的<code>URL</code>、获取未爬取的<code>URL</code>、添加新的<code>URL</code>到未爬取集合中、已爬取<code>URL</code>集合和未爬取<code>URL</code>集合的大小。</p>
<p><code>URL</code>管理器需要对爬取的<code>URL</code>进行去重处理，常见的去重方案有三种，分别是内存去重、关系数据库去重和缓存数据库去重。</p>
<p>两个变量<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.new_urls = set()</span><br><span class="line">self.old_urls = set()</span><br></pre></td></tr></table></figure></p>
<p>六个方法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">have_new_url(self)</span><br><span class="line">get_new_url(self)</span><br><span class="line">add_new_url(self, url)</span><br><span class="line">add_new_urls(self, urls)</span><br><span class="line">new_url_size(self)</span><br><span class="line">old_url_size(self)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">URLManager</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.new_urls = set()</span><br><span class="line">        self.old_urls = set()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">have_new_url</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        判断是否有待爬取的 url</span></span><br><span class="line"><span class="string">        :return: 待爬取的 url 集合的大小</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> self.new_url_size() != <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_new_url</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        获取待爬取的 url</span></span><br><span class="line"><span class="string">        :return: 一个待爬取的 url</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        new_url = self.new_urls.pop()</span><br><span class="line">        <span class="keyword">if</span> new_url <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            self.old_urls.add(new_url)</span><br><span class="line">            <span class="keyword">return</span> new_url</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_new_url</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        添加一个待爬取的 url</span></span><br><span class="line"><span class="string">        :param url:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> url <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> url <span class="keyword">not</span> <span class="keyword">in</span> self.new_urls <span class="keyword">and</span> url <span class="keyword">not</span> <span class="keyword">in</span> self.old_urls:</span><br><span class="line">            self.new_urls.add(url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_new_urls</span><span class="params">(self, urls)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        添加待爬取的 url 集合</span></span><br><span class="line"><span class="string">        :param urls:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> urls <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> len(urls) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            self.add_new_url(url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">new_url_size</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        待爬取的 url 集合的大小</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> len(self.new_urls)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">old_url_size</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        已爬取的 url 集合的大小</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> len(self.old_urls)</span><br></pre></td></tr></table></figure>
<h3 id="HTML下载器"><a href="#HTML下载器" class="headerlink" title="HTML下载器"></a><code>HTML</code>下载器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlDownloader</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> url <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        user_agent = <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) "</span> \</span><br><span class="line">                     <span class="string">"Chrome/71.0.3578.98 Safari/537.36"</span></span><br><span class="line">        headers = &#123;<span class="string">"User-Agent"</span>: user_agent&#125;</span><br><span class="line">        req = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> req.status_code == <span class="number">200</span>:</span><br><span class="line">            req.encoding = <span class="string">"utf-8"</span></span><br><span class="line">            <span class="keyword">return</span> req.text</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<h3 id="HTML解析器"><a href="#HTML解析器" class="headerlink" title="HTML解析器"></a><code>HTML</code>解析器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re, urlparse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlParser</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parser</span><span class="params">(self, page_url, html_content)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param page_url:</span></span><br><span class="line"><span class="string">        :param html_content:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> page_url <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> html_content <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        soup = BeautifulSoup(html_content, <span class="string">"lxml"</span>)</span><br><span class="line">        new_urls = self.get_new_urls(page_url, soup)</span><br><span class="line">        new_data = self.get_new_data(page_url, soup)</span><br><span class="line">        <span class="keyword">return</span> new_urls, new_data</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_new_urls</span><span class="params">(self, page_url, soup)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param page_url:</span></span><br><span class="line"><span class="string">        :param soup:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        new_urls = set()</span><br><span class="line">        links = soup.find_all(<span class="string">"a"</span>, href=re.compile(<span class="string">r'/item/(%\w+)+/\d+'</span>))</span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">            new_url = link[<span class="string">"href"</span>]</span><br><span class="line">            new_full_url = urlparse.urljoin(page_url, new_url)</span><br><span class="line">            new_urls.add(new_full_url)</span><br><span class="line">        <span class="keyword">return</span> new_urls</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_new_data</span><span class="params">(self, page_url, soup)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param page_url:</span></span><br><span class="line"><span class="string">        :param soup:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        data = &#123;&#125;</span><br><span class="line">        data[<span class="string">"url"</span>] = page_url.encode(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line">        title = soup.find(<span class="string">"dd"</span>, class_=<span class="string">"lemmaWgt-lemmaTitle-title"</span>).find(<span class="string">"h1"</span>)</span><br><span class="line">        data[<span class="string">"title"</span>] = title.string.encode(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line">        summary = soup.find(<span class="string">"div"</span>, class_=<span class="string">"lemma-summary"</span>)</span><br><span class="line">        data[<span class="string">"summary"</span>] = summary.get_text().encode(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<h3 id="数据存储器"><a href="#数据存储器" class="headerlink" title="数据存储器"></a>数据存储器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataOutput</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.datas = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">store_data</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> data <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.datas.append(data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">output_html</span><span class="params">(self)</span>:</span></span><br><span class="line">        headers = [<span class="string">"url"</span>, <span class="string">"title"</span>, <span class="string">"summary"</span>]</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">"baike.csv"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            fp_csv = csv.DictWriter(fp, headers)</span><br><span class="line">            fp_csv.writeheader()</span><br><span class="line">            fp_csv.writerows(self.datas)</span><br></pre></td></tr></table></figure>
<h3 id="爬虫调度器"><a href="#爬虫调度器" class="headerlink" title="爬虫调度器"></a>爬虫调度器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> URLManager <span class="keyword">import</span> URLManager</span><br><span class="line"><span class="keyword">from</span> HtmlDownloader <span class="keyword">import</span> HtmlDownloader</span><br><span class="line"><span class="keyword">from</span> HtmlParser <span class="keyword">import</span> HtmlParser</span><br><span class="line"><span class="keyword">from</span> DataOutput <span class="keyword">import</span> DataOutput</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.manager = URLManager()</span><br><span class="line">        self.downloader = HtmlDownloader()</span><br><span class="line">        self.parser = HtmlParser()</span><br><span class="line">        self.output = DataOutput()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">crawl</span><span class="params">(self, root_url)</span>:</span></span><br><span class="line">        self.manager.add_new_url(root_url)</span><br><span class="line">        <span class="keyword">while</span>(self.manager.have_new_url() <span class="keyword">and</span> self.manager.old_url_size() &lt; <span class="number">100</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                new_url = self.manager.get_new_url()</span><br><span class="line">                html = self.downloader.download(new_url)</span><br><span class="line">                new_urls, data = self.parser.parser(new_url, html)</span><br><span class="line">                self.manager.add_new_urls(new_urls)</span><br><span class="line">                self.output.store_data(data)</span><br><span class="line">                <span class="keyword">print</span> <span class="string">"已经爬取 %s 个链接"</span> % self.manager.old_url_size()</span><br><span class="line">            <span class="keyword">except</span> Exception, e:</span><br><span class="line">                <span class="keyword">print</span> <span class="string">"crawl failed."</span></span><br><span class="line">                <span class="keyword">print</span> e</span><br><span class="line">        self.output.output_html()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    spider = Spider()</span><br><span class="line">    spider.crawl(<span class="string">"https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB"</span>)</span><br></pre></td></tr></table></figure>

          <br>
<p> from yhw-miracle</p>
<p align="center"><img src="/images/qrcode_for_gh_5efb2780ab44_258.jpg" alt="痛点就是起点"></p>
<p align="center">算法和代码的世界不仅是学习的痛点，而且是成功的起点。欢迎关注，共同进步！</p>

        </section>
      </div>
      
      <!--<div class="block">
  
    <a class="main" href="/">Home</a>
  
    <a class="main" href="/ToYou">ToYou</a>
  
    <a class="main" href="/categories">Categories</a>
  
    <a class="main" href="/atom.xml">RSS</a>
  
</div>
-->
    </div>
    <footer>
  <span class="muted">&copy; 2016 - 2019 yhw-miracle. All Rights Reserved.</span><br>
  <!--<a href='https://github.com/saintwinkle/hexo-theme-scribble' class='muted'>built with Hexo using Scribble theme</a>-->
  <img src="/images/logo.jpg" width="53" height="59" alt="痛点就是起点">
</footer>

  </body>
</html>
